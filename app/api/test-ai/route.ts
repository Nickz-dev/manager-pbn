import { NextRequest, NextResponse } from 'next/server'
import OpenAI from 'openai'

// Initialize OpenAI client
const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY
})

export async function POST(request: NextRequest) {
  try {
    console.log('ü§ñ Testing OpenAI API connection...')
    
    // Check if API key is configured
    if (!process.env.OPENAI_API_KEY || process.env.OPENAI_API_KEY.includes('your_openai_api_key')) {
      return NextResponse.json(
        { error: 'OpenAI API –∫–ª—é—á –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω' },
        { status: 400 }
      )
    }

    const { 
      prompt, 
      temperature = 0.7, 
      max_tokens = 4000, 
      top_p = 0.9, 
      store_logs = true 
    } = await request.json()
    
    if (!prompt) {
      return NextResponse.json(
        { error: 'Prompt –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω' },
        { status: 400 }
      )
    }

    // Log generation parameters if store_logs is enabled
    if (store_logs) {
      console.log('üìä AI Generation Parameters:', {
        temperature,
        max_tokens,
        top_p,
        prompt_length: prompt.length
      })
    }

    // Test OpenAI API call with configurable parameters
    const completion = await openai.chat.completions.create({
      model: 'gpt-4',
      messages: [
        {
          role: 'system',
          content: '–¢—ã –æ–ø—ã—Ç–Ω—ã–π SEO-–∫–æ–ø–∏—Ä–∞–π—Ç–µ—Ä, —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—â–∏–π—Å—è –Ω–∞ —Å–æ–∑–¥–∞–Ω–∏–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –¥–ª—è —Å–∞–π—Ç–æ–≤ –ø—Ä–æ –æ–Ω–ª–∞–π–Ω –∫–∞–∑–∏–Ω–æ –∏ –∞–∑–∞—Ä—Ç–Ω—ã–µ –∏–≥—Ä—ã. –ü–∏—à–∏ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ. –í—Å–µ–≥–¥–∞ –≤–æ–∑–≤—Ä–∞—â–∞–π –æ—Ç–≤–µ—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –∏–ª–∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤.'
        },
        {
          role: 'user',
          content: prompt
        }
      ],
      max_tokens: Math.min(max_tokens, 8000), // –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –º–∞–∫—Å–∏–º—É–º
      temperature: Math.max(0, Math.min(temperature, 2)), // –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –æ—Ç 0 –¥–æ 2
      top_p: Math.max(0.1, Math.min(top_p, 1)), // –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –æ—Ç 0.1 –¥–æ 1
      presence_penalty: 0.1, // –ù–µ–±–æ–ª—å—à–æ–π —à—Ç—Ä–∞—Ñ –∑–∞ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è
      frequency_penalty: 0.1 // –ù–µ–±–æ–ª—å—à–æ–π —à—Ç—Ä–∞—Ñ –∑–∞ —á–∞—Å—Ç—ã–µ —Å–ª–æ–≤–∞
    })

    const generatedText = completion.choices[0]?.message?.content

    // Log usage statistics if store_logs is enabled
    if (store_logs) {
      console.log('üìà AI Generation Stats:', {
        prompt_tokens: completion.usage?.prompt_tokens,
        completion_tokens: completion.usage?.completion_tokens,
        total_tokens: completion.usage?.total_tokens,
        model: completion.model
      })
    }

    console.log('‚úÖ OpenAI API test successful')

    return NextResponse.json({
      success: true,
      generatedText,
      usage: completion.usage,
      model: completion.model,
      parameters: {
        temperature,
        max_tokens,
        top_p,
        store_logs
      }
    })

  } catch (error: any) {
    console.error('‚ùå OpenAI API test failed:', error)
    
    return NextResponse.json(
      { 
        error: '–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ OpenAI API',
        details: error.message
      },
      { status: 500 }
    )
  }
} 